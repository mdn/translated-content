---
title: BaseAudioContext
slug: Web/API/BaseAudioContext
tags:
  - API
  - Audio
  - BaseAudioContext
  - Interface
  - Reference
  - TopicStub
  - Web Audio API
translation_of: Web/API/BaseAudioContext
---
<div>{{APIRef("Web Audio API")}}</div>

<p>L'interface <code>BaseAudioContext</code> agit comme une définition de base pour les graphiques de traitement audio en ligne et hors ligne, comme représenté par {{domxref("AudioContext")}} et {{domxref("OfflineAudioContext")}} respectivement. Vous n'utiliseriez pas <code>BaseAudioContext</code> directement — vous utiliseriez ses fonctionnalités via l'une de ces deux interfaces héréditaires.</p>

<p>Un <code>BaseAudioContext</code> peut être une cible d'événements, il implémente donc l'interface {{domxref("EventTarget")}}.</p>

<p>{{InheritanceDiagram}}</p>

<h2 id="Propriétés">Propriétés</h2>

<dl>
 <dt>{{domxref("BaseAudioContext.audioWorklet")}} {{experimental_inline}} {{readonlyInline}}</dt>
 <dd>Renvoie l'objet {{domxref("AudioWorklet")}}, utilisé pour créer des AudioNodes personnalisés avec traitement JavaScript.</dd>
 <dt>{{domxref("BaseAudioContext.currentTime")}} {{readonlyInline}}</dt>
 <dd>Renvoie un double représentant une durée matérielle toujours croissante en secondes utilisée pour la planification. Il commence à <code>0</code>.</dd>
 <dt>{{domxref("BaseAudioContext.destination")}} {{readonlyInline}}</dt>
 <dd>Renvoie un {{domxref("AudioDestinationNode")}} représentant la destination finale de tout l'audio dans le contexte. Il peut être considéré comme le périphérique de rendu audio.</dd>
 <dt>{{domxref("BaseAudioContext.listener")}} {{readonlyInline}}</dt>
 <dd>Renvoie l'objet {{domxref("AudioListener")}}, utilisé pour la spatialisation 3D.</dd>
 <dt>{{domxref("BaseAudioContext.sampleRate")}} {{readonlyInline}}</dt>
 <dd>Renvoie un float représentant la fréquence d'échantillonnage (en échantillons par seconde) utilisée par tous les nœuds dans ce contexte. La fréquence d'échantillonnage d'un {{domxref("AudioContext")}} ne peut pas être modifiée.</dd>
 <dt>{{domxref("BaseAudioContext.state")}} {{readonlyInline}}</dt>
 <dd>Renvoie l'état actuel de l'<code>AudioContext</code>.</dd>
</dl>

<h3 id="Gestionnaires_dévénements">Gestionnaires d'événements</h3>

<dl>
 <dt>{{domxref("BaseAudioContext.onstatechange")}}</dt>
 <dd>Un gestionnaire d'événements qui s'exécute lorsqu'un événement de type {{event("statechange")}} s'est déclenché. Cela se produit lorsque l'état de l'<code>AudioContext</code> change, en raison de l'appel de l'une des méthodes de changement d'état ({{domxref("AudioContext.suspend")}}, {{domxref("AudioContext.resume")}}, ou {{domxref("AudioContext.close")}}).</dd>
</dl>

<h2 id="Méthodes">Méthodes</h2>

<p><em>Implémente également les méthodes de l'interface </em>{{domxref("EventTarget")}}.</p>

<dl>
 <dt>{{domxref("BaseAudioContext.createBuffer()")}}</dt>
 <dd>Crée un nouvel objet {{ domxref("AudioBuffer") }} vide, qui peut ensuite être rempli de données et lu via un {{ domxref("AudioBufferSourceNode") }}.</dd>
 <dt>{{domxref("BaseAudioContext.createConstantSource()")}}</dt>
 <dd>Crée un objet {{domxref("ConstantSourceNode")}}, qui est une source audio qui émet en continu un signal sonore monophonique (un canal) dont les échantillons ont tous la même valeur.</dd>
 <dt>{{domxref("BaseAudioContext.createBufferSource()")}}</dt>
 <dd>Crée un {{domxref("AudioBufferSourceNode")}}, qui peut être utilisé pour lire et manipuler des données audio contenues dans un objet {{ domxref("AudioBuffer") }}. Les {{ domxref("AudioBuffer") }} sont créés à l'aide de {{domxref("AudioContext.createBuffer")}} ou renvoyés par {{domxref("AudioContext.decodeAudioData")}} lorsqu'il décode avec succès une piste audio.</dd>
 <dt>{{domxref("BaseAudioContext.createScriptProcessor()")}}</dt>
 <dd>Crée un {{domxref("ScriptProcessorNode")}}, qui peut être utilisé pour le traitement audio direct via JavaScript.</dd>
 <dt>{{domxref("BaseAudioContext.createStereoPanner()")}}</dt>
 <dd>Crée un {{domxref("StereoPannerNode")}}, qui peut être utilisé pour appliquer un panoramique stéréo à une source audio.</dd>
 <dt>{{domxref("BaseAudioContext.createAnalyser()")}}</dt>
 <dd>Crée un {{domxref("AnalyserNode")}}, qui peut être utilisé pour exposer les données de temps et de fréquence audio et par exemple pour créer des visualisations de données.</dd>
 <dt>{{domxref("BaseAudioContext.createBiquadFilter()")}}</dt>
 <dd>Crée un {{domxref("BiquadFilterNode")}}, qui représente un filtre du second ordre configurable en plusieurs types de filtres courants: passe-haut, passe-bas, passe-bande, etc.</dd>
 <dt>{{domxref("BaseAudioContext.createChannelMerger()")}}</dt>
 <dd>Crée un {{domxref("ChannelMergerNode")}}, qui est utilisé pour combiner les canaux de plusieurs flux audio en un seul flux audio.</dd>
 <dt>{{domxref("BaseAudioContext.createChannelSplitter()")}}</dt>
 <dd>Crée un {{domxref("ChannelSplitterNode")}}, qui est utilisé pour accéder aux canaux individuels d'un flux audio et les traiter séparément.</dd>
 <dt>{{domxref("BaseAudioContext.createConvolver()")}}</dt>
 <dd>Crée un {{domxref("ConvolverNode")}}, qui peut être utilisé pour appliquer des effets de convolution à votre graphique audio, par exemple un effet de réverbération.</dd>
 <dt>{{domxref("BaseAudioContext.createDelay()")}}</dt>
 <dd>Crée un {{domxref("DelayNode")}}, qui est utilisé pour retarder le signal audio entrant d'une certaine quantité. Ce nœud est également utile pour créer des boucles de rétroaction dans un graphique d'API Web Audio.</dd>
 <dt>{{domxref("BaseAudioContext.createDynamicsCompressor()")}}</dt>
 <dd>Crée un {{domxref("DynamicsCompressorNode")}}, qui peut être utilisé pour appliquer une compression acoustique à un signal audio.</dd>
 <dt>{{domxref("BaseAudioContext.createGain()")}}</dt>
 <dd>Crée un {{domxref("GainNode")}}, qui peut être utilisé pour contrôler le volume global du graphique audio.</dd>
 <dt>{{domxref("BaseAudioContext.createIIRFilter()")}}</dt>
 <dd>Crée un {{domxref("IIRFilterNode")}}, qui représente un filtre du second ordre configurable en plusieurs types de filtres communs différents.</dd>
 <dt>{{domxref("BaseAudioContext.createOscillator()")}}</dt>
 <dd>Crée un {{domxref("OscillatorNode")}}, une source représentant une forme d'one périodique. Cela génère essentiellement un ton.</dd>
 <dt>{{domxref("BaseAudioContext.createPanner()")}}</dt>
 <dd>Crée un {{domxref("PannerNode")}}, qui est utilisé pour spatialiser un flux audio entrant dans l'espace 3D.</dd>
 <dt>{{domxref("BaseAudioContext.createPeriodicWave()")}}</dt>
 <dd>Crée un {{domxref("PeriodicWave")}}, utilisé pour définir une forme d'one périodique qui peut être utilisée pour déterminer la sortie d'un {{ domxref("OscillatorNode") }}.</dd>
 <dt>{{domxref("BaseAudioContext.createWaveShaper()")}}</dt>
 <dd>Crée un {{domxref("WaveShaperNode")}}, qui est utilisé pour implémenter des effets de distorsion non linéaires.</dd>
 <dt>{{domxref("BaseAudioContext.decodeAudioData()")}}</dt>
 <dd>Décode de manière asynchrone les données de fichiers audio contenues dans un {{domxref("ArrayBuffer")}}. Dans ce cas, le ArrayBuffer est généralement chargé à partir de l'attribut <code>response</code> d'un {{domxref("XMLHttpRequest")}} après avoir défini le <code>responseType</code> sur <code>arraybuffer</code>. Cette méthode ne foncionne que sur des fichiers complets et non sur des fragments de fichiers audio.</dd>
 <dt>{{domxref("BaseAudioContext.resume()")}}</dt>
 <dd>Reprend la progression du temps dans un contexte audio précédemment suspendu / mis en pause.</dd>
</dl>

<h2 id="Exemples">Exemples</h2>

<p>Déclaration de context audio de base:</p>

<pre class="brush: js">var audioCtx = new AudioContext();</pre>

<p>Variante de nagivateur croisé:</p>

<pre class="brush: js">var AudioContext = window.AudioContext || window.webkitAudioContext;
var audioCtx = new AudioContext();

var oscillatorNode = audioCtx.createOscillator();
var gainNode = audioCtx.createGain();
var finish = audioCtx.destination;
// etc.</pre>

<h2 id="Spécifications">Spécifications</h2>

<table class="standard-table">
 <tbody>
  <tr>
   <th scope="col">Spécification</th>
   <th scope="col">Statut</th>
   <th scope="col">Commentaire</th>
  </tr>
  <tr>
   <td>{{SpecName('Web Audio API', '#BaseAudioContext', 'BaseAudioContext')}}</td>
   <td>{{Spec2('Web Audio API')}}</td>
   <td></td>
  </tr>
 </tbody>
</table>

<h2 id="Compatibilité_des_navigateurs">Compatibilité des navigateurs</h2>

<p>{{Compat("api.BaseAudioContext")}}</p>

<h2 id="Voir_aussi">Voir aussi</h2>

<ul>
 <li><a href="/en-US/docs/Web_Audio_API/Using_Web_Audio_API">Utilisation de l'API Web Audio</a></li>
 <li>{{domxref("AudioContext")}}</li>
 <li>{{domxref("OfflineAudioContext")}}</li>
</ul>
